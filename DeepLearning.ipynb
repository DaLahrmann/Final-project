{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- used libraries of this file\n",
    "- `data_input` is a self defined file which will be used to transform the input data into usable variables\n",
    "- in `models_define` the hyperparameter definition of the Neural-Networks is implemented\n",
    "- all functions which can be used to solve the puzzle are defined  in  `sudoku_solve_algorithm` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import data_input as di\n",
    "import models_define as md\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import sudoku_solve_algorithm as sa\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- read data for the creating of the model\n",
    "- test split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('sudoku.csv')\n",
    "X_train, X_test, y_train, y_test=di.get_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "definition fitting and evaluating of the NN-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=md.get_Conv_model()\n",
    "model.compile(\n",
    "  optimizer='adam', #here we could use stochastic gradient descent, but adam is a de facto standard\n",
    "  loss='categorical_crossentropy', #this is how we create the original blame to play the blame game\n",
    "  metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "  X_train,\n",
    "  to_categorical(y_train), # just to make sure the outputs are not considered numeric (because, ya know, they are numbers...)\n",
    "  epochs=2, # go 2 times through the whole dataset\n",
    "  batch_size=32, # send 32 images at a time before you tweak the network again, to make it faster\n",
    ")\n",
    "\n",
    "model.evaluate(\n",
    "  X_test,\n",
    "  to_categorical(y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('big_sudoku_conv_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2=pd.read_csv('sudoku.csv').sample(100)\n",
    "X, y=di.get_data2(data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- computation of puzzle accuracy\n",
    "- speed and accuracy test of the slov solving method (insert each empty digit one by one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(sa)\n",
    "#model=keras.models.load_model('big_sudoku_conv_3')\n",
    "def test_accuracy(puz,y,model,solver):\n",
    "    \n",
    "    correct = 0\n",
    "    for i,x in enumerate(puz):\n",
    "        pred = solver(x,model)\n",
    "        real = y[i]+1\n",
    "        if abs(pred-real).sum()==0:\n",
    "            correct+=1\n",
    "    print(correct/len(puz))\n",
    "\n",
    "#test_accuracy(X,y,model,sa.fast_nn_solver)\n",
    "test_accuracy(X,y,model,sa.slow_nn_solver)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "speed test of the recursive solving method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lahrm\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4095\n",
      "4095\n",
      "3363\n",
      "2417\n",
      "12206\n",
      "19736\n",
      "3680\n",
      "1370\n",
      "15573\n",
      "2889\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(sa)\n",
    "sodu=data.quizzes.head(10)\n",
    "#print(sodu[0])\n",
    "for i in sodu.index:\n",
    "    data2, inds , solved=sa.bingo_solve(list(sodu[i]))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e956ae00da0b923c53eac0ba781c2d63e37e4818bc4e157197045199dda01c2a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
